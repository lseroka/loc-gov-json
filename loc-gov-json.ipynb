{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# encoding: utf-8\n",
    "\n",
    "# Pull Item and Resource CSVs from loc.gov JSON\n",
    "# Follow prompts in script for data inputs\n",
    "# See: https://staff.loc.gov/wikis/display/DCMSection/Pull+loc.gov+JSON+data+for+Items+and+Resources\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dcmhelpers import *\n",
    "from locgov import *\n",
    "import timeit\n",
    "\n",
    "# TO ADD:\n",
    "# output p1_item_id\n",
    "\n",
    "\n",
    "# Search loc.gov based on a starting seed URL\n",
    "def paged_search(seed, item_writer, resource_writer, catalog_option, locgov_server, segments_option_choice):\n",
    "    # search_counter = '10'\n",
    "    # current_page = 1\n",
    "    # # If basic search or if a collection, weed out unnecessary JSON parts\n",
    "    # if 'loc.gov/collections/' in seed:\n",
    "    #     exclude = '&at!=expert_resources,topics,featured_items,facet_views,views,pages,next,content,next_sibling,previous_sibling,facets'\n",
    "    # if 'loc.gov/search' in seed:\n",
    "    #     exclude = '&at!=views,facet_views,facets'\n",
    "    # # Build up the URL based on the excludes, results per page, and current page\n",
    "    # url_args = '&fo=json&all=true&c=' + search_counter + exclude\n",
    "    # url_page = '&sp=' + str(current_page)\n",
    "    # search_url = seed + url_args\n",
    "    # starter_url = search_url + url_page\n",
    "\n",
    "    search_counter = '10'\n",
    "    current_page = 1\n",
    "    url_args = '&fo=json&all=true&c=' + search_counter\n",
    "    url_page = '&sp=' + str(current_page)\n",
    "    search_url = seed + url_args\n",
    "    starter_url = search_url + '&at=pagination,search'\n",
    "\n",
    "    # Get the first page of results, to get info on total results and total pages\n",
    "    starter_search = locgov_search(starter_url)\n",
    "    totals = starter_search['search']\n",
    "    pages = starter_search['pagination']\n",
    "    total_pages = pages['total']\n",
    "\n",
    "    print('Search query: ', totals['in'])\n",
    "    print('Total hits: ', totals['hits'])\n",
    "    print('Total pages: ', total_pages)\n",
    "\n",
    "    if totals['hits'] == 0:\n",
    "        resultrow = {\n",
    "            'p1_item': seed,\n",
    "            'p1_resource' : 'NO RESULT FOR SEARCH'\n",
    "        }\n",
    "        item_writer.writerow(resultrow)\n",
    "        resource_writer.writerow(resultrow)\n",
    "        print(resultrow)\n",
    "    else:\n",
    "        # Proceed with search for each page of results\n",
    "        while current_page <= total_pages:\n",
    "            #this_url = search_url + url_page + exclude\n",
    "            this_url = search_url + url_page + '&at=results'\n",
    "            search = locgov_search(this_url)\n",
    "            results = search['results']\n",
    "            for result in results:\n",
    "                write_resource_rows(result, item_writer, resource_writer, catalog_option, locgov_server, segments_option_choice)\n",
    "            current_page += 1\n",
    "            url_page = '&sp=' + str(current_page)\n",
    "\n",
    "# Write the rows to the files for each search result\n",
    "def write_resource_rows(result, item_writer, resource_writer, catalog_option, locgov_server, segments_option_choice):\n",
    "    p1_item = result['id']\n",
    "    p1_item_id = p1_item.split('/')[-2]\n",
    "    # If not an item (such as a Framework page), skip\n",
    "    if 'item' not in p1_item and 'lccn.loc.gov' not in p1_item:\n",
    "        print('Not an item: ', p1_item)\n",
    "        return\n",
    "    # If its a catalog record, skip based on decision\n",
    "    if 'lccn.loc.gov' in p1_item and catalog_option == '2':\n",
    "        print('Skipping catalog item: ', p1_item)\n",
    "        return\n",
    "\n",
    "    # Pull all data out of the result JSON\n",
    "    p1_resources = []\n",
    "    digitized = ''\n",
    "    number_lccn = ''\n",
    "    number_fileID = ''\n",
    "    number_uuid = ''\n",
    "    online_format = []\n",
    "    mime_type = []\n",
    "    partof = []\n",
    "    group = []\n",
    "    if 'digitized' in result:\n",
    "        digitized = result['digitized']\n",
    "    if 'number_lccn' in result:\n",
    "        number_lccn = result['number_lccn']\n",
    "    if 'number_fileID' in result:\n",
    "        number_fileID = result['number_fileID']\n",
    "    if 'number_uuid' in result:\n",
    "        number_uuid = result['number_uuid']\n",
    "    if 'online_format' in result:\n",
    "        online_format = result['online_format']\n",
    "    if 'mime_type' in result:\n",
    "        mime_type = result['mime_type']\n",
    "    if 'partof' in result:\n",
    "        partof = result['partof']\n",
    "    if 'group' in result:\n",
    "        group = result['group']\n",
    "    if 'resources' in result and result['resources'] is not None:\n",
    "        for resource in result['resources']:\n",
    "            p1_resources.append(resource)\n",
    "    # print('p1 item: ', p1_item)\n",
    "    # print('p1 resources: ', p1_resources)\n",
    "    resultrow = {\n",
    "        'p1_item_id': p1_item_id,\n",
    "        'p1_item': p1_item,\n",
    "        'digitized': digitized,\n",
    "        'number_lccn': number_lccn,\n",
    "        'number_fileID': number_fileID,\n",
    "        'number_uuid': number_uuid,\n",
    "        'online_format': online_format,\n",
    "        'mime_type': mime_type,\n",
    "        'partof': partof,\n",
    "        'group': group,\n",
    "    }\n",
    "    if len(p1_resources) == 0:\n",
    "        resultrow.update({\n",
    "            'p1_resource': 'NONE',\n",
    "            'p1_resource_count': 0,\n",
    "        })\n",
    "        item_writer.writerow(resultrow)\n",
    "        #resource_writer.writerow(resultrow)\n",
    "        print(resultrow)\n",
    "        return\n",
    "\n",
    "    # For each of the resources, get data and write its own row\n",
    "    short_resources = []\n",
    "    for resource in p1_resources:\n",
    "        resourcerow = resultrow.copy()\n",
    "        p1_resource = ''\n",
    "        etl_aggregate = ''\n",
    "        p1_resource_id = ''\n",
    "        p1_resource_caption = ''\n",
    "        p1_resource_segment_count = 0\n",
    "        has_fulltext = False\n",
    "        if 'caption' in resource:\n",
    "            p1_resource_caption = resource['caption']\n",
    "        if 'segments' in resource:\n",
    "            p1_resource_segment_count = resource['segments']\n",
    "        elif 'files' in resource:\n",
    "            p1_resource_segment_count = resource['files']\n",
    "        if 'url' in resource:\n",
    "            p1_resource = resource['url']\n",
    "            p1_resource_section = p1_resource.split('/')[-2]\n",
    "            if '.' in p1_resource_section:\n",
    "                etl_aggregate, p1_resource_id = p1_resource_section.split('.', 1)\n",
    "        if 'fulltext_file' in resource and resource['fulltext_file'] != '':\n",
    "            has_fulltext = True\n",
    "\n",
    "        short_resources.append({\n",
    "            'p1_resource': p1_resource,\n",
    "            'p1_resource_caption': p1_resource_caption,\n",
    "            'p1_resource_segment_count': p1_resource_segment_count,\n",
    "        })\n",
    "\n",
    "        resourcerow.update({\n",
    "            'p1_resource': p1_resource,\n",
    "            'etl_aggregate': etl_aggregate,\n",
    "            'p1_resource_id': p1_resource_id,\n",
    "            'p1_resource_caption': p1_resource_caption,\n",
    "            'p1_resource_segment_count': p1_resource_segment_count,\n",
    "            'has_fulltext': has_fulltext\n",
    "        })\n",
    "        if 'representative_index' in resource:\n",
    "            resourcerow.update({\n",
    "                'representative_index': resource['representative_index']\n",
    "            })\n",
    "\n",
    "        if segments_option_choice == '2':\n",
    "            # Add more resource and segment data here\n",
    "            this_resource = None\n",
    "            p1_resource_segment_with_text = 0\n",
    "            if p1_resource != '':\n",
    "                full_resources = locgov_item_resources(p1_item_id, locgov_server)\n",
    "                for full_resource in full_resources:\n",
    "                    if 'url' in full_resource and full_resource['url'] == p1_resource:\n",
    "                        this_resource = full_resource\n",
    "            if this_resource != None:\n",
    "                for f in this_resource['files']:\n",
    "                    for s in f:\n",
    "                        if 'use' in s and s['use'] == 'text':\n",
    "                            p1_resource_segment_with_text += 1\n",
    "            resourcerow.update({\n",
    "                'p1_resource_segment_with_text': p1_resource_segment_with_text,\n",
    "            })\n",
    "\n",
    "\n",
    "        resource_writer.writerow(resourcerow)\n",
    "        print(resourcerow)\n",
    "    resultrow.update({\n",
    "        'p1_resource_count': len(short_resources),\n",
    "        'p1_resource': short_resources\n",
    "    })\n",
    "    item_writer.writerow(resultrow)\n",
    "    print(resultrow)\n",
    "\n",
    "\n",
    "valid_methods = ['1', '2', '3', '4', '5']\n",
    "search_inputs = ['1', '2', '3']\n",
    "file_inputs = ['4', '5']\n",
    "print('This script will return lists of loc.gov Items and Resources based on your criteria')\n",
    "method_prompt = \"\"\"\n",
    "Enter number for methods to get Items/Resources:\n",
    "    1. Enter loc.gov COLLECTION\n",
    "    2. Enter loc.gov PART OF\n",
    "    3. Enter loc.gov SEARCH QUERY\n",
    "    4. Select list of loc.gov ITEMS\n",
    "    5. Select list of loc.gov SEARCH QUERIES\"\"\"\n",
    "print(method_prompt)\n",
    "method_input = input()\n",
    "if method_input not in valid_methods:\n",
    "    print('Wrong input! : ', method_input)\n",
    "\n",
    "if method_input == '1':\n",
    "    collection_prompt = \"\"\"\n",
    "    Enter loc.gov COLLECTION\n",
    "        Input exactly as shown in loc.gov/collecton URL, including -'s\n",
    "        Ex: https://www.loc.gov/collections/rare-book-selections/\n",
    "        Enter: rare-book-selections\"\"\"\n",
    "    print(collection_prompt)\n",
    "    p1_collection = input()\n",
    "\n",
    "if method_input == '2':\n",
    "    partof_prompt = \"\"\"\n",
    "    Enter loc.gov PART OF\n",
    "        Input exactly as shown in loc.gov search URL, including +'s\n",
    "        Ex: https://www.loc.gov/search/?fa=partof:world+digital+library\n",
    "        Enter: world+digital+library\"\"\"\n",
    "    print(partof_prompt)\n",
    "    p1_partof = input()\n",
    "\n",
    "if method_input == '3':\n",
    "    search_prompt = \"\"\"\n",
    "    Enter loc.gov SEARCH QUERY\n",
    "        Input exactly as shown in loc.gov search URL, including +'s\n",
    "        Include quotes if required or if searching for exact identifier\n",
    "        This will also search full text of items so you may get unexpected results for broad searches!\n",
    "        Ex: https://www.loc.gov/search/?in=&q=\"france+in+america\"\n",
    "        Enter: \"france+in+america\" \"\"\"\n",
    "    print(search_prompt)\n",
    "    p1_search = input()\n",
    "\n",
    "if method_input == '4':\n",
    "    print('Select CSV file with item_id list')\n",
    "    print('Should match expected data to follow loc.gov/item/....')\n",
    "    item_file = getInputFileGUI(prompt=\"Select CSV file with item list: \")\n",
    "    required_input_fieldnames = ['item_id']\n",
    "    item_list = []\n",
    "    with open(item_file, 'r', encoding='utf-8-sig') as item_file:\n",
    "        reader = csv.DictReader(item_file)\n",
    "        testRequiredInput(reader.fieldnames, required_input_fieldnames)\n",
    "        for row in reader:\n",
    "            item_list.append(row['item_id'])\n",
    "\n",
    "if method_input == '5':\n",
    "    print('Select CSV file with query list')\n",
    "    print('Likely use case is a list of identifiers that do not match to item or resource urls')\n",
    "    query_file = getInputFileGUI(prompt=\"Select CSV file with query list: \")\n",
    "    required_input_fieldnames = ['query']\n",
    "    query_list = []\n",
    "    with open(query_file, 'r', encoding='utf-8-sig') as query_file:\n",
    "        reader = csv.DictReader(query_file)\n",
    "        testRequiredInput(reader.fieldnames, required_input_fieldnames)\n",
    "        for row in reader:\n",
    "            query_list.append(row['query'])\n",
    "\n",
    "segments_option_valid = ['1', '2']\n",
    "segments_option_prompt = \"\"\"\n",
    "Enter the number for whether to get full resource segment list.\n",
    "This will be much slower, but give more data. Use this for full text / transcription information.\n",
    "    1. Do NOT pull segments data (FASTER)\n",
    "    2. Pull segments data (SLOWER)\"\"\"\n",
    "print(segments_option_prompt)\n",
    "segments_option_choice = input()\n",
    "if segments_option_choice not in segments_option_valid:\n",
    "    print('Wrong input! : ', segments_option_choice)\n",
    "    exit()\n",
    "\n",
    "locgov_server_valid = ['1', '2', '3']\n",
    "locgov_server_prompt = \"\"\"\n",
    "Enter number for methods to get Items/Resources:\n",
    "    1. PRODUCTION (www.loc.gov)\n",
    "    2. TEST (test.loc.gov)\n",
    "    3. DEV (dev.loc.gov)\"\"\"\n",
    "print(locgov_server_prompt)\n",
    "locgov_server_choice = input()\n",
    "if locgov_server_choice not in locgov_server_valid:\n",
    "    print('Wrong input! : ', locgov_server_choice)\n",
    "    exit()\n",
    "\n",
    "if locgov_server_choice == '1':\n",
    "    locgov_server = 'www'\n",
    "if locgov_server_choice == '2':\n",
    "    locgov_server = 'test'\n",
    "if locgov_server_choice == '3':\n",
    "    locgov_server = 'dev'\n",
    "\n",
    "catalog_valid = ['1', '2']\n",
    "catalog_option_prompt = \"\"\"\n",
    "Enter number for whether to include lccn.loc.gov item\n",
    "    You may want to include this to find un-ETLed items that redirect to the Catalog\n",
    "    Probably don't include if you know you have a lot of expected un-ETLed items\n",
    "    Include lccn.loc.gov items?\n",
    "    1. YES\n",
    "    2. NO\"\"\"\n",
    "print(catalog_option_prompt)\n",
    "catalog_option = input()\n",
    "if catalog_option not in catalog_valid:\n",
    "    print('Wrong input! : ', catalog_option)\n",
    "\n",
    "\n",
    "print('Select output location for ITEMS list')\n",
    "item_output = getOutput(filename='loc_gov_items')\n",
    "item_output_fieldnames = ['p1_item_id', 'p1_item', 'p1_resource_count', 'p1_resource', 'digitized',\n",
    "    'number_lccn', 'number_fileID', 'number_uuid',\n",
    "    'online_format', 'mime_type', 'partof', 'group',\n",
    "]\n",
    "\n",
    "print('Select output location for RESOURCES list')\n",
    "resource_output = getOutput(filename='loc_gov_resources')\n",
    "resource_output_fieldnames = ['p1_item_id', 'p1_item', 'p1_resource', 'etl_aggregate', 'p1_resource_id',\n",
    "    'p1_resource_caption', 'p1_resource_segment_count', 'digitized',\n",
    "    'number_lccn', 'number_fileID', 'number_uuid',\n",
    "    'online_format', 'mime_type', 'partof', 'group',\n",
    "    'has_fulltext', 'representative_index',\n",
    "]\n",
    "\n",
    "if segments_option_choice == '2':\n",
    "    resource_output_fieldnames.append(\n",
    "        'p1_resource_segment_with_text'\n",
    "    )\n",
    "\n",
    "with open (item_output, 'w', encoding='utf-8-sig') as item_output:\n",
    "    item_writer = csv.DictWriter(item_output, fieldnames=item_output_fieldnames, lineterminator='\\n')\n",
    "    item_writer.writeheader()\n",
    "\n",
    "    with open (resource_output, 'w', encoding='utf-8-sig') as resource_output:\n",
    "        resource_writer = csv.DictWriter(resource_output, fieldnames=resource_output_fieldnames, lineterminator='\\n')\n",
    "        resource_writer.writeheader()\n",
    "\n",
    "        # Build the search seed URL based on input\n",
    "        if method_input in search_inputs:\n",
    "            if method_input == '1':\n",
    "                url_start = 'https://%s.loc.gov/collections/' % locgov_server\n",
    "                search_url = url_start + p1_collection + '/?'\n",
    "            if method_input == '2':\n",
    "                url_start = 'https://%s.loc.gov/search/?fa=partof:' % locgov_server\n",
    "                search_url = url_start + p1_partof\n",
    "            if method_input == '3':\n",
    "                url_start = 'https://%s.loc.gov/search/?q=' % locgov_server\n",
    "                search_url = url_start + p1_search\n",
    "\n",
    "            paged_search(search_url, item_writer, resource_writer, catalog_option, locgov_server, segments_option_choice)\n",
    "\n",
    "        # Get each item individually for item CSV\n",
    "        if method_input == '4':\n",
    "            for i in item_list:\n",
    "                item = locgov_item(i, locgov_server)\n",
    "                if item == 404:\n",
    "                    resultrow = {\n",
    "                        'p1_item': i,\n",
    "                        'p1_resource': 'INVALID'\n",
    "                    }\n",
    "                    item_writer.writerow(resultrow)\n",
    "                    resource_writer.writerow(resultrow)\n",
    "                    print(resultrow)\n",
    "                else:\n",
    "                    write_resource_rows(item, item_writer, resource_writer, catalog_option, locgov_server, segments_option_choice)\n",
    "\n",
    "        # Perform each search individually for search CSV\n",
    "        if method_input == '5':\n",
    "            for i in query_list:\n",
    "                url_start = 'https://%s.loc.gov/search/?q=' % locgov_server\n",
    "                i = i.replace(' ', '+')\n",
    "                search_url = url_start + '\"' + i + '\"'\n",
    "                paged_search(search_url, item_writer, resource_writer, catalog_option, locgov_server, segments_option_choice)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
